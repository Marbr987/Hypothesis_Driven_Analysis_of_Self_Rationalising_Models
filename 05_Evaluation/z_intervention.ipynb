{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "directory = 'vers33/MLP_Classifiers_480k_training_15_iter_NN_size_200_50_30'\n",
    "#use_z_values = tuple(range(25))\n",
    "#use_z_values = (0,6,12,18,24)\n",
    "use_z_values = (0,3,4,6,8,9,12,13,14,15,16,17,18,19,20,21,22,23,24)\n",
    "model_names = [\"S1-S2\",\n",
    "               \"S1-V2\",\n",
    "               \"S1-O2\",\n",
    "               \"S1-L2\",\n",
    "               \"S1-C2\",\n",
    "               \"V1-S2\",\n",
    "               \"V1-V2\",\n",
    "               \"V1-O2\",\n",
    "               \"V1-L2\",\n",
    "               \"V1-C2\",\n",
    "               \"O1-S2\",\n",
    "               \"O1-V2\",\n",
    "               \"O1-O2\",\n",
    "               \"O1-L2\",\n",
    "               \"O1-C2\",\n",
    "               \"L1-S2\",\n",
    "               \"L1-V2\",\n",
    "               \"L1-O2\",\n",
    "               \"L1-L2\",\n",
    "               \"L1-C2\",\n",
    "               \"C1-S2\",\n",
    "               \"C1-V2\",\n",
    "               \"C1-O2\",\n",
    "               \"C1-L2\",\n",
    "               \"C1-C2\",]\n",
    "model_names = [name for i,name in enumerate(model_names) if i in use_z_values]\n",
    "\n",
    "clf = list()\n",
    "for i in range(len(use_z_values)):\n",
    "    with open(\"../03_Bayesian_Network/\" + directory + \"/MLP_Classifier\" + str(i) + \".pkl\", \"rb\") as f:\n",
    "        clf += [pickle.load(f), ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('../Input_Data/e-SNLI/dataset/esnli_train_1.csv')\n",
    "train2 = pd.read_csv('../Input_Data/e-SNLI/dataset/esnli_train_2.csv')\n",
    "train = pd.concat([train1, train2])\n",
    "train = train[train.notnull().apply(all, axis=1)]\n",
    "dev = pd.read_csv('../Input_Data/e-SNLI/dataset/esnli_dev.csv')\n",
    "dev = dev[dev.notnull().apply(all, axis=1)]\n",
    "test = pd.read_csv('../Input_Data/e-SNLI/dataset/esnli_test.csv')\n",
    "test = test[test.notnull().apply(all, axis=1)]\n",
    "\n",
    "dev_prepared = pd.read_csv('../02_Extract_Subphrases/prepared_data/subphrase_vectors_dev.csv', sep=';')\n",
    "dev_prepared = dev_prepared.drop(columns='Unnamed: 0')\n",
    "dev = dev.set_index('pairID')\n",
    "rel_pairIDs = dev_prepared.iloc[:,0]\n",
    "y_hat = dev.loc[rel_pairIDs].gold_label\n",
    "dev_prepared = dev_prepared.iloc[:,1:].to_numpy()\n",
    "\n",
    "dev_subphrases = pd.read_csv('../02_Extract_Subphrases/prepared_data/subphrases_dev.csv', sep=',')\n",
    "dev_subphrases = dev_subphrases.set_index('pairID')\n",
    "dev_subphrases = dev_subphrases.loc[rel_pairIDs]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Prepare colum indices\n",
    "indices = np.array([[0,1500], [0,1800], [0,2100], [0,2400], [0,2700],\n",
    "                    [300,1500], [300,1800], [300,2100], [300,2400], [300,2700],\n",
    "                    [600,1500], [600,1800], [600,2100], [600,2400], [600,2700],\n",
    "                    [900,1500], [900,1800], [900,2100], [900,2400], [900,2700],\n",
    "                    [1200,1500], [1200,1800], [1200,2100], [1200,2400], [1200,2700]])\n",
    "indices = indices[use_z_values,:].tolist()\n",
    "# Initialise colulmn indices and \"nan\" values if information (e.g. location of sentence) is not detected\n",
    "not_nan = [None, ] * len(use_z_values)\n",
    "cols = [None, ] * len(use_z_values)\n",
    "for i in range(len(use_z_values)):\n",
    "    cols[i] = list(range(indices[i][0], indices[i][0]+300)) + list(range(indices[i][1],indices[i][1]+300))\n",
    "    not_nan[i] = pd.Series([not x for x in pd.DataFrame(np.isnan(dev_prepared[:,cols[i]])).apply(any, axis=1)])\n",
    "not_nan = np.array(not_nan).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Compute softmax values for each set of scores in x.\n",
    "    \"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def custom_sign(x):\n",
    "    if len(x.shape) == 2 and x.shape[1] == 1:\n",
    "        x = x.reshape((-1,))\n",
    "    else:\n",
    "        raise ValueError(f\"x must be of shape (n,1), not {x.shape}\")\n",
    "    return np.diag((np.sign(x) + 1) / 2) # np.sign returns 1 and -1, but we want 1 and 0\n",
    "\n",
    "def get_gradient(x1, x2, net, j):\n",
    "    x = np.vstack((x1, x2))\n",
    "    n_hidden = net.n_layers_ - 2 # number of hidden layers (subtract output and input layer)\n",
    "    n = x.shape[0]\n",
    "\n",
    "    # Get weights and biases from net\n",
    "    W = net.coefs_\n",
    "    W = [w.T for w in W]\n",
    "    b = net.intercepts_\n",
    "    b = [bt.reshape((-1,1)) for bt in b]\n",
    "\n",
    "    # Calculate the partial derivatives of each factor in the chain for the final gradient\n",
    "    # Forward propagation\n",
    "    h = [relu(W[0] @ x + b[0])]\n",
    "    for i in range(1, n_hidden):\n",
    "        h += [relu(W[i] @ h[i-1] + b[i])]\n",
    "    h += [softmax(W[n_hidden] @ h[-1] + b[-1])]\n",
    "\n",
    "    # Backward propagation\n",
    "    delta = np.zeros((net.n_outputs_, 1))\n",
    "    delta[j] = 1\n",
    "    gradients = [custom_sign(W[0] @ x + b[0]) @ W[0][:,int(n/2):], ]\n",
    "    for i in range(1, n_hidden):\n",
    "        gradients += [custom_sign(W[i] @ h[i-1] + b[i]) @ W[i], ]\n",
    "    gradients += [(softmax(W[-1] @ h[-2] + b[-1]) * (delta - softmax(W[-1] @ h[-2] + b[-1]))).T @ W[-1], ]\n",
    "\n",
    "    gradient = gradients[-1]\n",
    "    for i in range(n_hidden-1, -1, -1):\n",
    "        gradient = gradient @ gradients[i]\n",
    "    return gradient.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def pertubate_input(x1, x2, net, learning_rate=0.5):\n",
    "    x2_star = x2\n",
    "    z_hat_original = np.argmax(net.predict_proba(np.vstack((x1, x2)).T))\n",
    "    z_hat = z_hat_original\n",
    "    epsilon = 0\n",
    "    iterations = 0\n",
    "    while z_hat == z_hat_original:\n",
    "        iterations += 1\n",
    "        gradient = get_gradient(x1, x2_star, net, z_hat_original)\n",
    "        epsilon += learning_rate * -gradient\n",
    "        x2_star = x2 + epsilon\n",
    "        z_hat = np.argmax(net.predict_proba(np.vstack((x1, x2_star)).T))\n",
    "    return x2_star, epsilon, iterations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "4.160986167201184\n",
      "['contradiction']\n",
      "['entailment']\n",
      "embracing fighting\n",
      "['entailment']\n",
      "V1-V2\n",
      "674.6572885480628\n",
      "Changed from ('embracing', 'fighting') to ('embracing', 'dogfighting')\n"
     ]
    }
   ],
   "source": [
    "model_index = 3\n",
    "cur_x1 = dev_prepared[2,cols[model_index][:300]].reshape((-1,1))\n",
    "cur_x2 = dev_prepared[2,cols[model_index][300:]].reshape((-1,1))\n",
    "\n",
    "original_pred = clf[model_index].predict(np.vstack((cur_x1, cur_x2)).T)\n",
    "x2_star, epsilon, iterations = pertubate_input(cur_x1, cur_x2, clf[model_index])\n",
    "pert_pred = clf[model_index].predict(np.vstack((cur_x1, x2_star)).T)\n",
    "print(iterations)\n",
    "print(np.sum(epsilon * epsilon))\n",
    "print(original_pred)\n",
    "print(pert_pred)\n",
    "\n",
    "ms_x1 = nlp.vocab.strings[nlp.vocab.vectors.most_similar(cur_x1.T, n=1)[0][0]]\n",
    "ms_x2 = nlp.vocab.strings[nlp.vocab.vectors.most_similar(cur_x2.T, n=1)[0][0]]\n",
    "pos_x2 = nlp(ms_x2)[0].pos_\n",
    "print(ms_x1, ms_x2)\n",
    "ms_x2_star = [nlp.vocab.strings[id] for id in nlp.vocab.vectors.most_similar(x2_star.T, n=10)[0][0,:]]\n",
    "\n",
    "for term in ms_x2_star:\n",
    "    nlp_x2_star = nlp(term)[0]\n",
    "    pos_x2_star = nlp_x2_star.pos_\n",
    "    if pos_x2_star == pos_x2 and term != ms_x2:\n",
    "        ms_x2_star = term\n",
    "        x2_star = nlp_x2_star.vector.reshape((-1,1))\n",
    "        break\n",
    "pert_pred = clf[model_index].predict(np.vstack((cur_x1, x2_star)).T)\n",
    "\n",
    "\n",
    "while original_pred == pert_pred:\n",
    "    epsilon = 1.1 * epsilon\n",
    "    x2_star = cur_x2 + epsilon\n",
    "    ms_x2_star = [nlp.vocab.strings[id] for id in nlp.vocab.vectors.most_similar(x2_star.T, n=10)[0][0,:]]\n",
    "    for term in ms_x2_star:\n",
    "        nlp_x2_star = nlp(term)[0]\n",
    "        pos_x2_star = nlp_x2_star.pos_\n",
    "        if pos_x2_star == pos_x2 and term != ms_x2:\n",
    "            ms_x2_star = term\n",
    "            x2_star = nlp_x2_star.vector.reshape((-1,1))\n",
    "            break\n",
    "    pert_pred = clf[model_index].predict(np.vstack((cur_x1, x2_star)).T)\n",
    "epsilon = x2_star - cur_x2\n",
    "print(pert_pred)\n",
    "print(model_names[model_index])\n",
    "print(np.sum(epsilon * epsilon))\n",
    "print(f\"Changed from {ms_x1, ms_x2} to {ms_x1, ms_x2_star}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 6.0342e-02],\n       [-6.9463e-01],\n       [-1.9652e+00],\n       [ 2.3819e-01],\n       [ 1.5806e+00],\n       [ 1.1793e+00],\n       [ 1.6456e+00],\n       [ 2.2771e+00],\n       [-4.2130e-01],\n       [-7.6174e-01],\n       [ 1.9682e+00],\n       [ 7.3408e-01],\n       [-1.1922e+00],\n       [ 7.4786e-01],\n       [ 3.0677e+00],\n       [ 3.2473e+00],\n       [ 2.5065e+00],\n       [-1.6465e-01],\n       [-8.9224e-01],\n       [ 7.7612e-01],\n       [ 8.2401e-01],\n       [ 1.5025e+00],\n       [-1.9849e-01],\n       [ 6.5685e-01],\n       [ 1.7082e+00],\n       [-2.2786e-01],\n       [-2.5034e+00],\n       [-2.3373e+00],\n       [-1.6716e-01],\n       [-2.9230e-01],\n       [ 3.2595e+00],\n       [ 1.1605e+00],\n       [ 9.1680e-01],\n       [-1.1685e+00],\n       [ 1.4924e-02],\n       [-1.3162e+00],\n       [-3.0498e-01],\n       [ 2.4476e+00],\n       [-1.3953e-02],\n       [-8.1036e-01],\n       [ 7.5154e-01],\n       [-1.3571e+00],\n       [ 1.6972e-01],\n       [-5.6768e-01],\n       [-2.8128e+00],\n       [ 8.5635e-01],\n       [-1.2174e+00],\n       [-3.8110e+00],\n       [ 9.5594e-01],\n       [ 1.4626e-01],\n       [ 8.8741e-01],\n       [ 3.1487e+00],\n       [ 1.4634e+00],\n       [-2.1907e+00],\n       [-6.2400e-01],\n       [ 9.0126e-01],\n       [-8.6366e-01],\n       [ 4.3838e-01],\n       [ 1.1558e+00],\n       [-5.1355e-01],\n       [-7.6528e-01],\n       [ 6.7350e-01],\n       [-1.2488e+00],\n       [-1.5177e+00],\n       [ 2.7466e+00],\n       [ 2.1199e+00],\n       [-3.7687e+00],\n       [-1.2127e+00],\n       [ 9.3915e-01],\n       [ 2.3452e+00],\n       [ 1.0508e+00],\n       [-8.1788e-01],\n       [-2.7044e+00],\n       [ 4.4007e-01],\n       [-5.7543e-01],\n       [-2.9822e-01],\n       [-4.7381e-01],\n       [ 2.9369e+00],\n       [-1.0209e+00],\n       [-5.5553e-01],\n       [-4.0899e+00],\n       [-2.1534e+00],\n       [-1.3819e-02],\n       [ 3.9067e+00],\n       [ 1.3796e+00],\n       [-1.1427e+00],\n       [-5.6274e-01],\n       [-2.8706e+00],\n       [-1.6481e+00],\n       [ 6.3529e-01],\n       [-8.1927e-02],\n       [ 1.1741e+00],\n       [ 3.9359e-01],\n       [-2.0759e+00],\n       [ 7.7304e-02],\n       [-2.9678e+00],\n       [-7.8541e-01],\n       [-1.2575e+00],\n       [ 7.9296e-01],\n       [ 1.1373e+00],\n       [ 1.4009e-01],\n       [-5.1068e-01],\n       [ 5.5758e+00],\n       [ 1.8721e+00],\n       [-2.2271e+00],\n       [ 3.9204e+00],\n       [ 7.5890e-01],\n       [ 1.1550e+00],\n       [ 1.4750e-01],\n       [-2.9102e+00],\n       [ 4.4963e-01],\n       [-1.2447e+00],\n       [-1.3254e+00],\n       [ 1.8262e+00],\n       [ 1.0058e+00],\n       [ 1.1540e+00],\n       [-1.5222e+00],\n       [ 1.0177e+00],\n       [ 1.1569e+00],\n       [-1.0604e+00],\n       [-6.8675e-01],\n       [-2.2852e+00],\n       [ 9.0049e-01],\n       [-1.6540e+00],\n       [-2.2668e+00],\n       [-2.6802e+00],\n       [ 2.2953e+00],\n       [-3.2235e+00],\n       [ 7.4971e-01],\n       [-1.5316e+00],\n       [-9.6794e-01],\n       [-3.3423e-01],\n       [ 2.8011e+00],\n       [ 5.3620e-01],\n       [-1.4469e+00],\n       [ 1.2361e+00],\n       [-9.0252e-01],\n       [ 2.0843e-01],\n       [ 2.0867e+00],\n       [-7.4626e-01],\n       [-1.2050e-01],\n       [-1.5327e-01],\n       [-3.1046e+00],\n       [ 2.2926e+00],\n       [ 2.2373e+00],\n       [ 9.1617e-01],\n       [-3.9436e+00],\n       [-1.4060e+00],\n       [ 8.7756e-01],\n       [ 1.0505e+00],\n       [ 9.7461e-01],\n       [ 3.5820e-01],\n       [-5.9195e-01],\n       [ 1.5412e+00],\n       [-8.8895e-01],\n       [ 1.0495e-01],\n       [ 2.6359e+00],\n       [-4.0724e-01],\n       [-3.9997e-01],\n       [-2.4531e+00],\n       [-7.6766e-01],\n       [-9.4018e-01],\n       [ 2.1129e+00],\n       [ 6.4883e-01],\n       [-1.7760e+00],\n       [-1.2719e+00],\n       [-1.3374e+00],\n       [-1.1102e-01],\n       [-4.2322e-01],\n       [ 1.3169e+00],\n       [-9.5980e-01],\n       [ 2.0371e+00],\n       [ 1.3438e+00],\n       [-2.2508e+00],\n       [ 4.6759e-01],\n       [ 1.3795e+00],\n       [ 6.1318e-01],\n       [ 2.2386e-02],\n       [-1.2411e+00],\n       [-1.4294e+00],\n       [-2.5215e+00],\n       [ 2.8216e-01],\n       [ 1.6461e-01],\n       [ 1.2819e+00],\n       [-8.5485e-01],\n       [ 2.6925e+00],\n       [-1.6989e+00],\n       [ 7.0535e-01],\n       [-1.0827e+00],\n       [-9.9596e-01],\n       [ 3.6635e-01],\n       [-7.7620e-01],\n       [ 5.5634e-01],\n       [-1.3470e+00],\n       [ 2.4059e+00],\n       [-1.7699e+00],\n       [-2.4884e+00],\n       [ 1.4249e+00],\n       [-1.4334e-01],\n       [ 1.0792e+00],\n       [ 7.1445e-01],\n       [-3.1974e-01],\n       [ 1.7020e-02],\n       [-3.1328e-01],\n       [ 2.1427e+00],\n       [ 1.4822e+00],\n       [-2.1067e+00],\n       [-1.3840e-01],\n       [-7.2558e-01],\n       [ 4.2627e-02],\n       [-1.7642e-02],\n       [ 4.0266e-01],\n       [-2.8729e+00],\n       [-1.6928e-01],\n       [-2.0207e-01],\n       [ 2.2968e+00],\n       [ 3.3575e+00],\n       [-2.4111e-01],\n       [-1.2912e+00],\n       [-5.1618e-01],\n       [-1.1011e+00],\n       [ 1.6674e+00],\n       [-6.5275e-01],\n       [ 1.4794e+00],\n       [-1.7823e+00],\n       [-1.3142e-01],\n       [ 9.7944e-01],\n       [ 6.4201e-02],\n       [ 3.8950e-01],\n       [ 1.8181e-01],\n       [ 2.4734e+00],\n       [-6.8478e-01],\n       [-3.8032e-01],\n       [ 2.4087e+00],\n       [ 8.4995e-01],\n       [-5.0362e-01],\n       [-1.3384e+00],\n       [ 8.6164e-01],\n       [-1.2945e+00],\n       [-4.4708e-01],\n       [ 1.9222e-01],\n       [ 9.7187e-02],\n       [-1.3583e-01],\n       [-6.6101e-02],\n       [-2.3665e+00],\n       [ 8.8468e-02],\n       [-2.5923e+00],\n       [-9.1903e-01],\n       [-1.0390e+00],\n       [ 1.6658e+00],\n       [ 2.2315e+00],\n       [-2.5214e+00],\n       [-2.4154e+00],\n       [ 9.0189e-01],\n       [-1.2987e+00],\n       [-1.0564e+00],\n       [-1.4325e-03],\n       [-1.0113e+00],\n       [ 6.2145e-01],\n       [ 2.2460e+00],\n       [-1.9886e+00],\n       [ 8.8257e-01],\n       [ 3.5727e+00],\n       [ 9.0793e-01],\n       [-8.4857e-01],\n       [-5.9061e-01],\n       [-4.0088e-01],\n       [ 7.7129e-01],\n       [ 7.5619e-01],\n       [-6.6550e-01],\n       [ 1.9101e-01],\n       [-6.5155e-01],\n       [-1.2016e+00],\n       [-1.6948e-01],\n       [ 6.6607e-01],\n       [ 1.9397e-01],\n       [ 2.9906e-01],\n       [-2.6647e+00],\n       [ 1.2379e+00],\n       [ 2.2268e+00],\n       [-7.4356e-01],\n       [-3.0678e-01],\n       [ 7.6542e-01],\n       [-1.8424e-02],\n       [ 3.2128e-01],\n       [ 5.4522e-01],\n       [-1.1507e+00],\n       [ 7.1069e-01],\n       [-1.8593e+00],\n       [ 1.4128e+00],\n       [ 9.9500e-01],\n       [ 1.2346e+00],\n       [-3.1659e-01],\n       [ 8.0711e-01],\n       [-2.3846e+00],\n       [ 6.9549e-02],\n       [ 5.6281e-02],\n       [-2.5772e+00],\n       [-1.5092e+00],\n       [-8.3241e-01]], dtype=float32)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_star.reshape((-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 300",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcur_x1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx2_star\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mT\n",
      "File \u001B[0;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mvstack\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/.conda/envs/master_thesis_code/lib/python3.10/site-packages/numpy/core/shape_base.py:296\u001B[0m, in \u001B[0;36mvstack\u001B[0;34m(tup, dtype, casting)\u001B[0m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arrs, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    295\u001B[0m     arrs \u001B[38;5;241m=\u001B[39m [arrs]\n\u001B[0;32m--> 296\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_nx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcasting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcasting\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mconcatenate\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 300"
     ]
    }
   ],
   "source": [
    "np.vstack((cur_x1, x2_star)).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "['activewear',\n 'promoting',\n 'responsorial',\n 'promote',\n 'broadminded',\n 'dedicating',\n 'promotees',\n 'responsory',\n 'respons',\n 'mobilizing']"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nlp.vocab.strings[id] for id in nlp.vocab.vectors.most_similar(x2_star.T, n=10)[0][0,:]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "array([10844699138153907478,  1027099120411152061,  2080108370443471494,\n       11790474613361244676,  6892858849450375015,  6553990832704373837,\n         804403426522879558, 16942184799860767510, 15444821592234117941,\n       17462773503239410202], dtype=uint64)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.most_similar(x2_star.T, n=10)[0][0,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "outputs": [
    {
     "data": {
      "text/plain": "1749.379310202855"
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(cur_x1 * cur_x1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "contradiction\n",
      "contradiction\n",
      "1\n",
      "neutral\n",
      "neutral\n",
      "2\n",
      "contradiction\n",
      "contradiction\n",
      "3\n",
      "neutral\n",
      "neutral\n",
      "4\n",
      "neutral\n",
      "neutral\n",
      "5\n",
      "contradiction\n",
      "contradiction\n",
      "6\n",
      "neutral\n",
      "neutral\n",
      "7\n",
      "contradiction\n",
      "contradiction\n",
      "8\n",
      "neutral\n",
      "neutral\n",
      "9\n",
      "neutral\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    cur_inp = np.random.rand(600).reshape((1,-1)) * 4\n",
    "    pred = clf.predict(cur_inp)[0]\n",
    "    pert_pred = clf.predict(deepfool(cur_inp, clf, num_classes=3, overshoot=0.02, max_iter=50)[-1])[0]\n",
    "    if pert_pred == pred:\n",
    "        print(i)\n",
    "        print(pred)\n",
    "        print(pert_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['entailment'], dtype='<U13')"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "(600,)"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([5, ] * 600).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "(600,)"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient(np.array([5, ] * 600), clf).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}