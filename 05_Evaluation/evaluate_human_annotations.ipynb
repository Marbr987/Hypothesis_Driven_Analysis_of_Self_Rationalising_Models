{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def predict_y_from_z(z):\n",
    "\n",
    "    # Iterate through each row if z is a matrix\n",
    "    if len(z.shape) > 1:\n",
    "        z = pd.DataFrame(z)\n",
    "        res = z.apply(predict_y_from_z, axis=1)\n",
    "        return res.to_numpy()\n",
    "\n",
    "    # For each single line perform the following:\n",
    "    else:\n",
    "        # If any z is 'contradiction' -> output class 'contradiction'\n",
    "        if any(z == 'contradiction'):\n",
    "            return 'contradiction'\n",
    "        # Else if all subphrases of sentence 2 are entailed by any subphrase of sentence 1 -> output class 'entailment'\n",
    "        elif all([any([z[i] == 'entailment' for i in subphrase_indices]) or all([z[i] == 'nan' or pd.isnull(z[i]) for i in subphrase_indices]) for subphrase_indices in Sentence2_indices]):\n",
    "            return 'entailment'\n",
    "        # Else output class 'neutral'\n",
    "        else:\n",
    "            return 'neutral'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "h1 = pd.read_excel(\"evaluation_template_h1.xlsx\")\n",
    "use_indices = ~h1.subphrase_correctness_SSM_small.isnull()\n",
    "h1 = h1[use_indices]\n",
    "h1 = h1.drop(columns=h1.columns[11:21]).fillna(0)\n",
    "\n",
    "h2 = pd.read_excel(\"evaluation_template_h2.xlsx\")\n",
    "h2 = h2[use_indices]\n",
    "h2 = h2.drop(columns=h2.columns[11:21]).fillna(0)\n",
    "\n",
    "h3 = pd.read_excel(\"evaluation_template_h3.xlsx\")\n",
    "h3 = h3[use_indices]\n",
    "h3 = h3.drop(columns=h3.columns[11:21]).fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('../Input_Data/e-SNLI/dataset/esnli_train_1.csv')\n",
    "train2 = pd.read_csv('../Input_Data/e-SNLI/dataset/esnli_train_2.csv')\n",
    "train = pd.concat([train1, train2])\n",
    "train = train[train.notnull().apply(all, axis=1)]\n",
    "dev = pd.read_csv('../Input_Data/e-SNLI/dataset/esnli_dev.csv')\n",
    "dev = dev[dev.notnull().apply(all, axis=1)]\n",
    "test = pd.read_csv('../Input_Data/e-SNLI/dataset/esnli_test.csv')\n",
    "test = test[test.notnull().apply(all, axis=1)]\n",
    "\n",
    "dev_prepared = pd.read_csv('../02_Extract_Subphrases/prepared_data/subphrase_vectors_dev.csv', sep=';')\n",
    "dev_prepared = dev_prepared.drop(columns='Unnamed: 0')\n",
    "dev = dev.set_index('pairID')\n",
    "rel_pairIDs = dev_prepared.iloc[:,0]\n",
    "y_hat = dev.loc[rel_pairIDs].gold_label\n",
    "dev_prepared = dev_prepared.iloc[:,1:].to_numpy()\n",
    "dev_prepared = dev_prepared[h1.i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "BN_dev_small = pd.read_csv(\"../04_BN_Explanations/BN_explanations_small_model.csv\", sep=\";\", index_col=0)\n",
    "BN_dev_small = BN_dev_small.iloc[h3.i].reset_index()\n",
    "BN_dev_large = pd.read_csv(\"../04_BN_Explanations/BN_explanations_large_model.csv\", sep=\";\", index_col=0)\n",
    "BN_dev_large = BN_dev_large.iloc[h3.i].reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dev = dev.loc[rel_pairIDs]\n",
    "dev = dev.iloc[BN_dev_large.i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "temp = [None, ] * 10\n",
    "for i in range(1, 11):\n",
    "    temp[i - 1] = pd.read_csv(\"../01_GPT3_Explanations/prepared_data/GPT3_explanations\" + str(i) + \".csv\", sep=\";\")\n",
    "gpt3_dev = pd.concat(temp).set_index(\"pairID\")\n",
    "gpt3_dev = gpt3_dev.loc[rel_pairIDs]\n",
    "gpt3_dev = gpt3_dev.iloc[h3.i].reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dev_subphrases = pd.read_csv('../02_Extract_Subphrases/prepared_data/subphrases_dev.csv', sep=',')\n",
    "dev_subphrases = dev_subphrases.set_index('pairID')\n",
    "dev_subphrases = dev_subphrases.loc[rel_pairIDs]\n",
    "dev_subphrases = dev_subphrases.drop(\"Unnamed: 0\", axis=1)\n",
    "dev_subphrases = dev_subphrases.iloc[h3.i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "h = h1[h1.columns[11:]] + h2[h2.columns[11:]] + h3[h3.columns[11:]]\n",
    "h = h.applymap(lambda x: 1 if x >= 2 else 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def transform_z(Z):\n",
    "    res = np.zeros((dev_prepared.shape[0], 10), dtype=\"int\")\n",
    "    for j in range(Z.shape[0]):\n",
    "        y_hat_pred = predict_y_from_z(Z[j,:])\n",
    "        pairs = [[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n",
    "                 [1, 0], [1, 1], [1, 2], [1, 3], [1, 4],\n",
    "                 [2, 0], [2, 1], [2, 2], [2, 3], [2, 4],\n",
    "                 [3, 0], [3, 1], [3, 2], [3, 3], [3, 4],\n",
    "                 [4, 0], [4, 1], [4, 2], [4, 3], [4, 4]]\n",
    "        if y_hat_pred == 'neutral':\n",
    "            for i, subphrase_indices in enumerate(Sentence2_indices):\n",
    "                if all([Z[j,k] == 'neutral' or Z[j,k] == 'nan' or pd.isnull(Z[j,k]) for k in subphrase_indices]) and any([Z[j,k] == 'neutral' for k in subphrase_indices]):\n",
    "                    res[j,i+5] = 1\n",
    "        elif y_hat_pred == 'contradiction':\n",
    "            for i,z in enumerate(Z[j,:]):\n",
    "                if z == 'contradiction':\n",
    "                    res[j,pairs[use_z_values[i]][0]] = 1\n",
    "                    res[j,pairs[use_z_values[i]][1]+5] = 1\n",
    "        elif y_hat_pred == 'entailment':\n",
    "            for i,z in enumerate(Z[j,:]):\n",
    "                if z == 'entailment':\n",
    "                    res[j,pairs[use_z_values[i]][0]] = 1\n",
    "                    res[j,pairs[use_z_values[i]][1]+5] = 1\n",
    "    return res\n",
    "\n",
    "for k in range(2):\n",
    "    if k == 0:\n",
    "        directory = 'vers33/MLP_Classifiers_480k_training_15_iter_NN_size_200_50_30'\n",
    "        use_z_values = (0, 3, 4, 6, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24)\n",
    "    elif k == 1:\n",
    "        directory = 'vers31/MLP_Classifiers_480k_training_15_iter_NN_size_200_50_30'\n",
    "        use_z_values = tuple(range(25))\n",
    "\n",
    "    # Indices in terms of z for all hidden variables that are not mixed, e.g. Subject1-Subject2, Verb1-Verb2, etc.\n",
    "    non_mixed_pairs_indices = [i for i in range(len(use_z_values)) if use_z_values[i] in (0, 6, 12, 18, 24)]\n",
    "    # Indices for all z variables influenced by Subject2 (Verb2, Object2 etc. respectively) (e.g. Subject1-Subject2)\n",
    "    Subj2_indices = [i for i in range(len(use_z_values)) if use_z_values[i] in (0, 5, 10, 15, 20)]\n",
    "    Verb2_indices = [i for i in range(len(use_z_values)) if use_z_values[i] in (1, 6, 11, 16, 21)]\n",
    "    Obj2_indices = [i for i in range(len(use_z_values)) if use_z_values[i] in (2, 7, 12, 17, 22)]\n",
    "    Loc2_indices = [i for i in range(len(use_z_values)) if use_z_values[i] in (3, 8, 13, 18, 23)]\n",
    "    Clo2_indices = [i for i in range(len(use_z_values)) if use_z_values[i] in (4, 9, 14, 19, 24)]\n",
    "    Sentence2_indices = [Subj2_indices, Verb2_indices, Obj2_indices, Loc2_indices, Clo2_indices]\n",
    "\n",
    "    clf = list()\n",
    "    for i in range(len(use_z_values)):\n",
    "        with open(\"../03_Bayesian_Network/\" + directory + \"/MLP_Classifier\" + str(i) + \".pkl\", \"rb\") as f:\n",
    "            clf += [pickle.load(f), ]\n",
    "\n",
    "    # Prepare colum indices\n",
    "    indices = np.array([[0,1500], [0,1800], [0,2100], [0,2400], [0,2700],\n",
    "                        [300,1500], [300,1800], [300,2100], [300,2400], [300,2700],\n",
    "                        [600,1500], [600,1800], [600,2100], [600,2400], [600,2700],\n",
    "                        [900,1500], [900,1800], [900,2100], [900,2400], [900,2700],\n",
    "                        [1200,1500], [1200,1800], [1200,2100], [1200,2400], [1200,2700]])\n",
    "    indices = indices[use_z_values,:].tolist()\n",
    "\n",
    "    # Initialise colulmn indices and \"nan\" values if information (e.g. location of sentence) is not detected\n",
    "    not_nan = [None, ] * len(use_z_values)\n",
    "    cols = [None, ] * len(use_z_values)\n",
    "    for i in range(len(use_z_values)):\n",
    "        cols[i] = list(range(indices[i][0], indices[i][0]+300)) + list(range(indices[i][1],indices[i][1]+300))\n",
    "        not_nan[i] = pd.Series([not x for x in pd.DataFrame(np.isnan(dev_prepared[:,cols[i]])).apply(any, axis=1)])\n",
    "    not_nan = np.array(not_nan).T\n",
    "\n",
    "    z = np.empty((dev_prepared.shape[0], len(use_z_values)), dtype=np.dtype('U25'))\n",
    "    z[:,:] = np.nan\n",
    "\n",
    "    for i in range(len(use_z_values)):\n",
    "        z[not_nan[:,i], i] = clf[i].predict(dev_prepared[not_nan[:,i],:][:, cols[i]])\n",
    "    if k == 0:\n",
    "        z_small = transform_z(z)\n",
    "    elif k == 1:\n",
    "        z_large = transform_z(z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "jaccard_sim_small = list()\n",
    "jaccard_sim_large = list()\n",
    "for i in range(z_small.shape[0]):\n",
    "    jaccard_sim_small += [jaccard_score(z_small[i,:], h[h.columns[:10]].to_numpy()[i,:])]\n",
    "    jaccard_sim_large += [jaccard_score(z_large[i,:], h[h.columns[:10]].to_numpy()[i,:])]\n",
    "jaccard_sim_small = np.array(jaccard_sim_small)\n",
    "jaccard_sim_large = np.array(jaccard_sim_large)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "index_correct_small_SSM_preds = np.where(BN_dev_small.y_hat_BN == gpt3_dev.pred_label)[0]\n",
    "index_incorrect_small_SSM_preds = np.where(BN_dev_small.y_hat_BN != gpt3_dev.pred_label)[0]\n",
    "index_correct_large_SSM_preds = np.where(BN_dev_large.y_hat_BN == gpt3_dev.pred_label)[0]\n",
    "index_incorrect_large_SSM_preds = np.where(BN_dev_large.y_hat_BN != gpt3_dev.pred_label)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4234837092731829, (0.44510939510939507 / 0.409688013136289)\n",
      "0.3840601503759399, (0.42049319727891155 / 0.42473347547974416)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{jaccard_sim_small.mean()}, ({jaccard_sim_small[index_correct_small_SSM_preds].mean()} / {jaccard_sim_small[index_incorrect_small_SSM_preds].mean()})\")\n",
    "print(f\"{jaccard_sim_large.mean()}, ({jaccard_sim_small[index_correct_large_SSM_preds].mean()} / {jaccard_sim_small[index_incorrect_large_SSM_preds].mean()})\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "subj1_present                      0.526316\nverb1_present                      0.536842\nobj1_present                       0.210526\nloc1_present                       0.147368\nclo1_present                       0.115789\nsubj2_present                      0.547368\nverb2_present                      0.663158\nobj2_present                       0.294737\nloc2_present                       0.242105\nclo2_present                       0.084211\nstructure                          0.842105\nsupport                            0.968421\ncorrectness_GPT3                   0.863158\nfull_correctness_SSM_large         0.210526\nsubphrase_correctness_SSM_large    0.273684\nfull_correctness_SSM_small         0.273684\nsubphrase_correctness_SSM_small    0.368421\ndtype: float64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "full_correctness_SSM_small         0.243243\nsubphrase_correctness_SSM_small    0.351351\ndtype: float64"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.iloc[index_correct_small_SSM_preds][['full_correctness_SSM_small', 'subphrase_correctness_SSM_small']].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "full_correctness_SSM_large         0.250000\nsubphrase_correctness_SSM_large    0.285714\ndtype: float64"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.iloc[index_correct_large_SSM_preds][['full_correctness_SSM_large', 'subphrase_correctness_SSM_large']].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}