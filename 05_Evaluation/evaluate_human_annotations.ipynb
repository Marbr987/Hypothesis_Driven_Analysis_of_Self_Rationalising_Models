{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def predict_y_from_z(z):\n",
    "\n",
    "    # Iterate through each row if z is a matrix\n",
    "    if len(z.shape) > 1:\n",
    "        z = pd.DataFrame(z)\n",
    "        res = z.apply(predict_y_from_z, axis=1)\n",
    "        return res.to_numpy()\n",
    "\n",
    "    # For each single line perform the following:\n",
    "    else:\n",
    "        # If any z is 'contradiction' -> output class 'contradiction'\n",
    "        if any(z == 'contradiction'):\n",
    "            return 'contradiction'\n",
    "        # Else if all subphrases of sentence 2 are entailed by any subphrase of sentence 1 -> output class 'entailment'\n",
    "        elif all([any([z[i] == 'entailment' for i in subphrase_indices]) or all([z[i] == 'nan' or pd.isnull(z[i]) for i in subphrase_indices]) for subphrase_indices in Sentence2_indices]):\n",
    "            return 'entailment'\n",
    "        # Else output class 'neutral'\n",
    "        else:\n",
    "            return 'neutral'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "h1 = pd.read_excel(\"evaluation_template_h1.xlsx\")\n",
    "use_indices = ~h1.subphrase_correctness_SSM_small.isnull()\n",
    "h1 = h1[use_indices]\n",
    "h1 = h1.drop(columns=h1.columns[11:21]).fillna(0)\n",
    "\n",
    "h2 = pd.read_excel(\"evaluation_template_h2.xlsx\")\n",
    "h2 = h2[use_indices]\n",
    "h2 = h2.drop(columns=h2.columns[11:21]).fillna(0)\n",
    "\n",
    "h3 = pd.read_excel(\"evaluation_template_h3.xlsx\")\n",
    "h3 = h3[use_indices]\n",
    "h3 = h3.drop(columns=h3.columns[11:21]).fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('../Input_Data/e-SNLI/dataset/esnli_train_1.csv')\n",
    "train2 = pd.read_csv('../Input_Data/e-SNLI/dataset/esnli_train_2.csv')\n",
    "train = pd.concat([train1, train2])\n",
    "train = train[train.notnull().apply(all, axis=1)]\n",
    "dev = pd.read_csv('../Input_Data/e-SNLI/dataset/esnli_dev.csv')\n",
    "dev = dev[dev.notnull().apply(all, axis=1)]\n",
    "test = pd.read_csv('../Input_Data/e-SNLI/dataset/esnli_test.csv')\n",
    "test = test[test.notnull().apply(all, axis=1)]\n",
    "\n",
    "dev_prepared = pd.read_csv('../02_Extract_Subphrases/prepared_data/subphrase_vectors_dev.csv', sep=';')\n",
    "dev_prepared = dev_prepared.drop(columns='Unnamed: 0')\n",
    "dev = dev.set_index('pairID')\n",
    "rel_pairIDs = dev_prepared.iloc[:,0]\n",
    "y_hat = dev.loc[rel_pairIDs].gold_label\n",
    "dev_prepared = dev_prepared.iloc[:,1:].to_numpy()\n",
    "dev_prepared = dev_prepared[h1.i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "BN_dev_small = pd.read_csv(\"../04_BN_Explanations/BN_explanations_small_model.csv\", sep=\";\", index_col=0)\n",
    "BN_dev_small = BN_dev_small.iloc[h3.i].reset_index()\n",
    "BN_dev_large = pd.read_csv(\"../04_BN_Explanations/BN_explanations_large_model.csv\", sep=\";\", index_col=0)\n",
    "BN_dev_large = BN_dev_large.iloc[h3.i].reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "dev = dev.loc[rel_pairIDs]\n",
    "dev = dev.iloc[BN_dev_large.i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "temp = [None, ] * 10\n",
    "for i in range(1, 11):\n",
    "    temp[i - 1] = pd.read_csv(\"../01_GPT3_Explanations/prepared_data/GPT3_explanations\" + str(i) + \".csv\", sep=\";\")\n",
    "gpt3_dev = pd.concat(temp).set_index(\"pairID\")\n",
    "gpt3_dev = gpt3_dev.loc[rel_pairIDs]\n",
    "gpt3_dev = gpt3_dev.iloc[h3.i].reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "dev_subphrases = pd.read_csv('../02_Extract_Subphrases/prepared_data/subphrases_dev.csv', sep=',')\n",
    "dev_subphrases = dev_subphrases.set_index('pairID')\n",
    "dev_subphrases = dev_subphrases.loc[rel_pairIDs]\n",
    "dev_subphrases = dev_subphrases.drop(\"Unnamed: 0\", axis=1)\n",
    "dev_subphrases = dev_subphrases.iloc[h3.i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "h = h1[h1.columns[11:]] + h2[h2.columns[11:]] + h3[h3.columns[11:]]\n",
    "h = h.applymap(lambda x: 1 if x >= 2 else 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def transform_z(Z):\n",
    "    res = np.zeros((dev_prepared.shape[0], 10), dtype=\"int\")\n",
    "    for j in range(Z.shape[0]):\n",
    "        y_hat_pred = predict_y_from_z(Z[j,:])\n",
    "        pairs = [[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n",
    "                 [1, 0], [1, 1], [1, 2], [1, 3], [1, 4],\n",
    "                 [2, 0], [2, 1], [2, 2], [2, 3], [2, 4],\n",
    "                 [3, 0], [3, 1], [3, 2], [3, 3], [3, 4],\n",
    "                 [4, 0], [4, 1], [4, 2], [4, 3], [4, 4]]\n",
    "        if y_hat_pred == 'neutral':\n",
    "            for i, subphrase_indices in enumerate(Sentence2_indices):\n",
    "                if all([Z[j,k] == 'neutral' or Z[j,k] == 'nan' or pd.isnull(Z[j,k]) for k in subphrase_indices]) and any([Z[j,k] == 'neutral' for k in subphrase_indices]):\n",
    "                    res[j,i+5] = 1\n",
    "        elif y_hat_pred == 'contradiction':\n",
    "            for i,z in enumerate(Z[j,:]):\n",
    "                if z == 'contradiction':\n",
    "                    res[j,pairs[use_z_values[i]][0]] = 1\n",
    "                    res[j,pairs[use_z_values[i]][1]+5] = 1\n",
    "        elif y_hat_pred == 'entailment':\n",
    "            for i,z in enumerate(Z[j,:]):\n",
    "                if z == 'entailment':\n",
    "                    res[j,pairs[use_z_values[i]][0]] = 1\n",
    "                    res[j,pairs[use_z_values[i]][1]+5] = 1\n",
    "    return res\n",
    "\n",
    "for k in range(2):\n",
    "    if k == 0:\n",
    "        directory = 'vers33/MLP_Classifiers_480k_training_15_iter_NN_size_200_50_30'\n",
    "        use_z_values = (0, 3, 4, 6, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24)\n",
    "    elif k == 1:\n",
    "        directory = 'vers31/MLP_Classifiers_480k_training_15_iter_NN_size_200_50_30'\n",
    "        use_z_values = tuple(range(25))\n",
    "\n",
    "    # Indices in terms of z for all hidden variables that are not mixed, e.g. Subject1-Subject2, Verb1-Verb2, etc.\n",
    "    non_mixed_pairs_indices = [i for i in range(len(use_z_values)) if use_z_values[i] in (0, 6, 12, 18, 24)]\n",
    "    # Indices for all z variables influenced by Subject2 (Verb2, Object2 etc. respectively) (e.g. Subject1-Subject2)\n",
    "    Subj2_indices = [i for i in range(len(use_z_values)) if use_z_values[i] in (0, 5, 10, 15, 20)]\n",
    "    Verb2_indices = [i for i in range(len(use_z_values)) if use_z_values[i] in (1, 6, 11, 16, 21)]\n",
    "    Obj2_indices = [i for i in range(len(use_z_values)) if use_z_values[i] in (2, 7, 12, 17, 22)]\n",
    "    Loc2_indices = [i for i in range(len(use_z_values)) if use_z_values[i] in (3, 8, 13, 18, 23)]\n",
    "    Clo2_indices = [i for i in range(len(use_z_values)) if use_z_values[i] in (4, 9, 14, 19, 24)]\n",
    "    Sentence2_indices = [Subj2_indices, Verb2_indices, Obj2_indices, Loc2_indices, Clo2_indices]\n",
    "\n",
    "    clf = list()\n",
    "    for i in range(len(use_z_values)):\n",
    "        with open(\"../03_Bayesian_Network/\" + directory + \"/MLP_Classifier\" + str(i) + \".pkl\", \"rb\") as f:\n",
    "            clf += [pickle.load(f), ]\n",
    "\n",
    "    # Prepare colum indices\n",
    "    indices = np.array([[0,1500], [0,1800], [0,2100], [0,2400], [0,2700],\n",
    "                        [300,1500], [300,1800], [300,2100], [300,2400], [300,2700],\n",
    "                        [600,1500], [600,1800], [600,2100], [600,2400], [600,2700],\n",
    "                        [900,1500], [900,1800], [900,2100], [900,2400], [900,2700],\n",
    "                        [1200,1500], [1200,1800], [1200,2100], [1200,2400], [1200,2700]])\n",
    "    indices = indices[use_z_values,:].tolist()\n",
    "\n",
    "    # Initialise colulmn indices and \"nan\" values if information (e.g. location of sentence) is not detected\n",
    "    not_nan = [None, ] * len(use_z_values)\n",
    "    cols = [None, ] * len(use_z_values)\n",
    "    for i in range(len(use_z_values)):\n",
    "        cols[i] = list(range(indices[i][0], indices[i][0]+300)) + list(range(indices[i][1],indices[i][1]+300))\n",
    "        not_nan[i] = pd.Series([not x for x in pd.DataFrame(np.isnan(dev_prepared[:,cols[i]])).apply(any, axis=1)])\n",
    "    not_nan = np.array(not_nan).T\n",
    "\n",
    "    z = np.empty((dev_prepared.shape[0], len(use_z_values)), dtype=np.dtype('U25'))\n",
    "    z[:,:] = np.nan\n",
    "\n",
    "    for i in range(len(use_z_values)):\n",
    "        z[not_nan[:,i], i] = clf[i].predict(dev_prepared[not_nan[:,i],:][:, cols[i]])\n",
    "    if k == 0:\n",
    "        z_small = transform_z(z)\n",
    "    elif k == 1:\n",
    "        z_large = transform_z(z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "jaccard_sim_small = list()\n",
    "jaccard_sim_large = list()\n",
    "for i in range(z_small.shape[0]):\n",
    "    jaccard_sim_small += [jaccard_score(z_small[i,:], h[h.columns[:10]].to_numpy()[i,:])]\n",
    "    jaccard_sim_large += [jaccard_score(z_large[i,:], h[h.columns[:10]].to_numpy()[i,:])]\n",
    "jaccard_sim_small = np.array(jaccard_sim_small)\n",
    "jaccard_sim_large = np.array(jaccard_sim_large)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "index_correct_small_SSM_preds = np.where(BN_dev_small.y_hat_BN == gpt3_dev.pred_label)[0]\n",
    "index_incorrect_small_SSM_preds = np.where(BN_dev_small.y_hat_BN != gpt3_dev.pred_label)[0]\n",
    "index_correct_large_SSM_preds = np.where(BN_dev_large.y_hat_BN == gpt3_dev.pred_label)[0]\n",
    "index_incorrect_large_SSM_preds = np.where(BN_dev_large.y_hat_BN != gpt3_dev.pred_label)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4456140350877192, (0.4716216216216216 / 0.4290229885057471)\n",
      "0.35918546365914794, (0.3392857142857143 / 0.367501776830135)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{jaccard_sim_small.mean()}, ({jaccard_sim_small[index_correct_small_SSM_preds].mean()} / {jaccard_sim_small[index_incorrect_small_SSM_preds].mean()})\")\n",
    "print(f\"{jaccard_sim_large.mean()}, ({jaccard_sim_large[index_correct_large_SSM_preds].mean()} / {jaccard_sim_large[index_incorrect_large_SSM_preds].mean()})\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "subj1_present                      0.526316\nverb1_present                      0.536842\nobj1_present                       0.210526\nloc1_present                       0.147368\nclo1_present                       0.115789\nsubj2_present                      0.547368\nverb2_present                      0.663158\nobj2_present                       0.294737\nloc2_present                       0.242105\nclo2_present                       0.084211\nstructure                          0.842105\nsupport                            0.968421\ncorrectness_GPT3                   0.863158\nfull_correctness_SSM_large         0.210526\nsubphrase_correctness_SSM_large    0.273684\nfull_correctness_SSM_small         0.273684\nsubphrase_correctness_SSM_small    0.368421\ndtype: float64"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "full_correctness_SSM_small         0.293103\nsubphrase_correctness_SSM_small    0.379310\ndtype: float64"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.iloc[index_incorrect_small_SSM_preds][['full_correctness_SSM_small', 'subphrase_correctness_SSM_small']].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "full_correctness_SSM_small         0.243243\nsubphrase_correctness_SSM_small    0.351351\ndtype: float64"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.iloc[index_correct_small_SSM_preds][['full_correctness_SSM_small', 'subphrase_correctness_SSM_small']].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "full_correctness_SSM_large         0.194030\nsubphrase_correctness_SSM_large    0.268657\ndtype: float64"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.iloc[index_incorrect_large_SSM_preds][['full_correctness_SSM_large', 'subphrase_correctness_SSM_large']].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "full_correctness_SSM_large         0.250000\nsubphrase_correctness_SSM_large    0.285714\ndtype: float64"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.iloc[index_correct_large_SSM_preds][['full_correctness_SSM_large', 'subphrase_correctness_SSM_large']].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "0.85"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[h.obj1_present == 1].verb1_present.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "0     1\n1     0\n2     1\n3     0\n7     0\n11    0\n13    1\n14    1\n16    0\n20    0\n23    1\n24    0\n28    1\n31    0\n32    0\n33    0\n39    0\n41    0\n43    0\n46    0\n48    1\n51    1\n52    0\n54    0\n57    1\n62    0\n68    0\n71    1\n75    0\n79    0\n80    0\n82    0\n87    0\n89    1\n91    0\n92    1\n94    1\nName: subphrase_correctness_SSM_small, dtype: int64"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.iloc[index_correct_small_SSM_preds].subphrase_correctness_SSM_small"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "entailment       15\ncontradiction    10\nneutral          10\nName: y_hat_BN, dtype: int64"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BN_dev_small.iloc[np.where(h.subphrase_correctness_SSM_small == 1)[0]].y_hat_BN.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[5, 0],\n        [5, 0],\n        [2, 3],\n        [2, 3],\n        [2, 3],\n        [3, 2],\n        [3, 2],\n        [3, 2],\n        [3, 2],\n        [3, 2]]),\n array([0, 1]))"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['subj1_present', 'verb1_present', 'obj1_present', 'loc1_present',\n       'clo1_present', 'subj2_present', 'verb2_present', 'obj2_present',\n       'loc2_present', 'clo2_present', 'structure', 'support',\n       'correctness_GPT3', 'full_correctness_SSM_large',\n       'subphrase_correctness_SSM_large', 'full_correctness_SSM_small',\n       'subphrase_correctness_SSM_small'],\n      dtype='object')"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj1_present 0.7330671398994378\n",
      "verb1_present 0.8442158616577218\n",
      "obj1_present 0.6037031615925053\n",
      "loc1_present 0.48048002430502745\n",
      "clo1_present 0.7227626459143964\n",
      "subj2_present 0.6609497372856148\n",
      "verb2_present 0.6302702702702698\n",
      "obj2_present 0.5725657591139821\n",
      "loc2_present 0.5155502392344495\n",
      "clo2_present 0.6773584905660378\n",
      "structure 0.31603419829008506\n",
      "support 0.08584905660377305\n",
      "correctness_GPT3 0.28705440900562823\n",
      "full_correctness_SSM_large 0.5219404186795485\n",
      "subphrase_correctness_SSM_large 0.541035428844089\n",
      "full_correctness_SSM_small 0.5532915360501564\n",
      "subphrase_correctness_SSM_small 0.5944450300411086\n"
     ]
    }
   ],
   "source": [
    "for col in h.columns:\n",
    "    temp = np.array([h1[col], h2[col], h3[col]]).T\n",
    "    temp = aggregate_raters(temp)[0]\n",
    "    print(col, fleiss_kappa(temp, method='fleiss'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_correctness_SSM_large 0.40128296507483946\n",
      "subphrase_correctness_SSM_large 0.5714285714285712\n",
      "full_correctness_SSM_small 0.6926424050632908\n",
      "subphrase_correctness_SSM_small 0.726408450704225\n"
     ]
    }
   ],
   "source": [
    "for col, i in zip(['full_correctness_SSM_large', 'subphrase_correctness_SSM_large', 'full_correctness_SSM_small', 'subphrase_correctness_SSM_small'], [index_correct_large_SSM_preds, index_correct_large_SSM_preds, index_correct_small_SSM_preds, index_correct_small_SSM_preds]):\n",
    "    temp = np.array([h1[col].iloc[i], h2[col].iloc[i], h3[col].iloc[i]]).T\n",
    "    temp = aggregate_raters(temp)[0]\n",
    "    print(col, fleiss_kappa(temp, method='fleiss'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_correctness_SSM_large 0.5771388499298736\n",
      "subphrase_correctness_SSM_large 0.5244084682440849\n",
      "full_correctness_SSM_small 0.4682964094728799\n",
      "subphrase_correctness_SSM_small 0.5117845117845117\n"
     ]
    }
   ],
   "source": [
    "for col, i in zip(['full_correctness_SSM_large', 'subphrase_correctness_SSM_large', 'full_correctness_SSM_small', 'subphrase_correctness_SSM_small'], [index_incorrect_large_SSM_preds, index_incorrect_large_SSM_preds, index_incorrect_small_SSM_preds, index_incorrect_small_SSM_preds]):\n",
    "    temp = np.array([h1[col].iloc[i], h2[col].iloc[i], h3[col].iloc[i]]).T\n",
    "    temp = aggregate_raters(temp)[0]\n",
    "    print(col, fleiss_kappa(temp, method='fleiss'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}